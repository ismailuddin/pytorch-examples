{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU accelerated neural network using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 100\n",
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "N_CLASSES = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "HIDDEN_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(\n",
    "    root=\"../data/\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(np.arange(0, len(dataset)))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_loader = DataLoader(dataset, BATCH_SIZE, sampler=train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_loader = DataLoader(dataset, BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer_2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(X.size(0), -1)\n",
    "        X = self.layer_1(X)\n",
    "        X = F.relu(X)\n",
    "        return self.layer_2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel(WIDTH * HEIGHT, HIDDEN_SIZE, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader:\n",
    "    def __init__(self, data_loader, device):\n",
    "        self.data_loader = data_loader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            yield to_device(batch, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, get_default_device())\n",
    "val_loader = DeviceDataLoader(val_loader, get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_preds: torch.Tensor, y_true: torch.Tensor):\n",
    "    return torch.sum(y_preds == y_true).item() / y_true.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "history = {\n",
    "    \"loss\": [],\n",
    "    \"acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": [],    \n",
    "}\n",
    "for i in range(N_EPOCHS):\n",
    "    _loss = []\n",
    "    _acc = []\n",
    "    _val_loss = []\n",
    "    _val_acc = []\n",
    "    _batch_sizes = []\n",
    "    _val_batch_sizes = []\n",
    "    \n",
    "\n",
    "    # Training\n",
    "    for Xb, yb in train_loader:\n",
    "        logits = model(Xb)\n",
    "        loss = F.cross_entropy(logits, yb)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "        # Metrics\n",
    "        _loss.append(loss.detach().numpy())\n",
    "        y_prob = F.softmax(logits, dim=1)\n",
    "        y_pred_prob, y_preds = torch.max(y_prob, dim=1)\n",
    "        acc = accuracy(y_preds, yb)\n",
    "        _acc.append(acc)\n",
    "        _batch_sizes.append(len(Xb))\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            logits = model(Xb)\n",
    "            val_loss = F.cross_entropy(logits, yb).detach().numpy()\n",
    "            _val_loss.append(val_loss)\n",
    "            y_prob = F.softmax(logits, dim=1)\n",
    "            y_pred_prob, y_preds = torch.max(y_prob, dim=1)\n",
    "            val_acc = accuracy(y_preds, yb)\n",
    "            _val_acc.append(val_acc)\n",
    "            _val_batch_sizes.append(len(Xb))\n",
    "            \n",
    "        \n",
    "        # Weighted sum of losses to take into account non-equal batch sizes\n",
    "        _loss = np.sum(np.multiply(_loss, _batch_sizes)) / np.sum(_batch_sizes)\n",
    "        _val_loss = np.sum(np.multiply(_val_loss, _val_batch_sizes)) / np.sum(_val_batch_sizes)\n",
    "        \n",
    "        history[\"loss\"].append(_loss)\n",
    "        history[\"acc\"].append(torch.Tensor(_acc).mean().item())\n",
    "        history[\"val_acc\"].append(torch.Tensor(_val_acc).mean().item())\n",
    "        history[\"val_loss\"].append(_val_loss)\n",
    "        print(f\"Epoch: {i + 1}/{N_EPOCHS}, acc: {history['acc'][-1]:.4f}, loss: {history['loss'][-1]:.4f}, val_acc: {history['val_acc'][-1]:.4f},  val_loss: {history['val_loss'][-1]:.4f}\\r\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "metric = \"acc\"\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax.plot(\n",
    "    np.arange(0, len(history[f\"{metric}\"])), history[f\"{metric}\"], label=f\"{metric}\"\n",
    ")\n",
    "ax.plot(\n",
    "    np.arange(0, len(history[f\"val_{metric}\"])),\n",
    "    history[f\"val_{metric}\"],\n",
    "    label=f\"Validation {metric}\",\n",
    ")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
