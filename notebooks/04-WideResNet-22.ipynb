{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide ResNet (ConvNet) model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, data_loader, device):\n",
    "        self.data_loader = data_loader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            yield to_device(batch, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 5000\n",
    "BATCH_SIZE = 8\n",
    "N_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "train_transformers = tt.Compose(\n",
    "    [\n",
    "        tt.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n",
    "        tt.RandomHorizontalFlip(),\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize(*stats),\n",
    "    ]\n",
    ")\n",
    "validation_transformers = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(\n",
    "    os.path.join(\"../data\", \"cifar10\", \"train\"), transform=train_transformers\n",
    ")\n",
    "validation_dataset = ImageFolder(\n",
    "    os.path.join(\"../data\", \"cifar10\", \"test\"), transform=validation_transformers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_dataloader, get_default_device())\n",
    "val_loader = DeviceDataLoader(validation_dataloader, get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_preds: torch.Tensor, y_true: torch.Tensor):\n",
    "    return torch.sum(y_preds == y_true).item() / y_true.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d(\n",
    "    input_channels: int, output_channels: int, stride: int = 1, kernel_size: int = 3\n",
    "):\n",
    "    return nn.Conv2d(\n",
    "        in_channels=input_channels,\n",
    "        out_channels=output_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        stride=stride,\n",
    "        padding=kernel_size // 2,\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def batch_norm_conv_2d(input_channels: int, output_channels: int):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "        conv_2d(input_channels, output_channels),\n",
    "    )\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels: int, output_channels: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "        self.batch_norm = nn.BatchNorm2d(input_channels)\n",
    "        self.conv_1 = conv_2d(input_channels, output_channels, stride)\n",
    "        self.conv_2 = batch_norm_conv_2d(output_channels, output_channels)\n",
    "        self.shortcut = lambda x: x\n",
    "        if input_channels != output_channels:\n",
    "            self.shortcut = conv_2d(\n",
    "                input_channels, output_channels, stride, kernel_size=1\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm(x), inplace=True)\n",
    "        r = self.shortcut(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x) * 0.2\n",
    "        return x.add_(r)\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_groups: int,\n",
    "        n_res_blocks_per_group: int,\n",
    "        n_classes: int,\n",
    "        channel_multiplier: int,\n",
    "        initial_n_channels: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_groups = n_groups\n",
    "        self.n_classes = n_classes\n",
    "        self.n_res_blocks_per_group = n_res_blocks_per_group\n",
    "        self.initial_n_channels = initial_n_channels\n",
    "        self.channel_multiplier = channel_multiplier\n",
    "        self.layers = []\n",
    "        self.model = None\n",
    "        self.build_model()\n",
    "\n",
    "    def conv_2d(\n",
    "        self, input_channels: int, output_channels: int, kernel_size: int, stride: int\n",
    "    ):\n",
    "        return nn.Conv2d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=output_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=kernel_size // 2,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def build_group(\n",
    "        self,\n",
    "        n_res_blocks_per_group: int,\n",
    "        input_channels: int,\n",
    "        output_channels: int,\n",
    "        stride: int,\n",
    "    ):\n",
    "        group = []\n",
    "        first_block = ResidualBlock(input_channels, output_channels, stride)\n",
    "        group.append(first_block)\n",
    "        for i in range(1, n_res_blocks_per_group):\n",
    "            group.append(ResidualBlock(output_channels, output_channels))\n",
    "        return group\n",
    "\n",
    "    def calc_n_channels(self, index: int) -> int:\n",
    "        if index == 0:\n",
    "            return self.initial_n_channels\n",
    "        return self.initial_n_channels * (2 ** index) * self.channel_multiplier\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = [\n",
    "            self.conv_2d(\n",
    "                input_channels=3,\n",
    "                output_channels=self.initial_n_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "            )\n",
    "        ]\n",
    "        for i in range(self.n_groups):\n",
    "            stride = 2 if i > 0 else 1\n",
    "            self.layers.extend(\n",
    "                self.build_group(\n",
    "                    self.n_res_blocks_per_group,\n",
    "                    self.calc_n_channels(i),\n",
    "                    self.calc_n_channels(i + 1),\n",
    "                    stride,\n",
    "                )\n",
    "            )\n",
    "        self.layers.extend(\n",
    "            [\n",
    "                nn.BatchNorm2d(self.calc_n_channels(self.n_groups)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                Flatten(),\n",
    "                nn.Linear(self.calc_n_channels(self.n_groups), self.n_classes),\n",
    "            ]\n",
    "        )\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideResNet(\n",
    "    n_groups=3,\n",
    "    n_res_blocks_per_group=3,\n",
    "    n_classes=10,\n",
    "    channel_multiplier=6,\n",
    "    initial_n_channels=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(model, get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "history = {\n",
    "    \"loss\": [],\n",
    "    \"acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": [],\n",
    "}\n",
    "for i in range(N_EPOCHS):\n",
    "    _loss = []\n",
    "    _acc = []\n",
    "    _val_loss = []\n",
    "    _val_acc = []\n",
    "    _batch_sizes = []\n",
    "    _val_batch_sizes = []\n",
    "\n",
    "\n",
    "    # Training\n",
    "    for Xb, yb in tqdm(train_loader):\n",
    "        logits = model(Xb)\n",
    "        loss = F.cross_entropy(logits, yb)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "        # Metrics\n",
    "        _loss.append(loss.detach().numpy())\n",
    "        y_prob = F.softmax(logits, dim=1)\n",
    "        y_pred_prob, y_preds = torch.max(y_prob, dim=1)\n",
    "        acc = accuracy(y_preds, yb)\n",
    "        _acc.append(acc)\n",
    "        _batch_sizes.append(len(Xb))\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            logits = model(Xb)\n",
    "            val_loss = F.cross_entropy(logits, yb).detach().numpy()\n",
    "            _val_loss.append(val_loss)\n",
    "            y_prob = F.softmax(logits, dim=1)\n",
    "            y_pred_prob, y_preds = torch.max(y_prob, dim=1)\n",
    "            val_acc = accuracy(y_preds, yb)\n",
    "            _val_acc.append(val_acc)\n",
    "            _val_batch_sizes.append(len(Xb))\n",
    "\n",
    "\n",
    "        # Weighted sum of losses to take into account non-equal batch sizes\n",
    "        _loss = np.sum(np.multiply(_loss, _batch_sizes)) / np.sum(_batch_sizes)\n",
    "        _val_loss = np.sum(np.multiply(_val_loss, _val_batch_sizes)) / np.sum(_val_batch_sizes)\n",
    "\n",
    "        history[\"loss\"].append(_loss)\n",
    "        history[\"acc\"].append(torch.Tensor(_acc).mean().item())\n",
    "        history[\"val_acc\"].append(torch.Tensor(_val_acc).mean().item())\n",
    "        history[\"val_loss\"].append(_val_loss)\n",
    "        print(f\"Epoch: {i + 1}/{N_EPOCHS}, acc: {history['acc'][-1]:.4f}, loss: {history['loss'][-1]:.4f}, val_acc: {history['val_acc'][-1]:.4f},  val_loss: {history['val_loss'][-1]:.4f}\\r\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
